{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6384be0",
   "metadata": {},
   "source": [
    "# Race Results Normalization with Pydantic\n",
    "\n",
    "This notebook demonstrates how to use Pydantic models to normalize race results data from multiple sources into a consistent, analyzable format. This enables writing general-purpose analysis code that works across different races and data sources.\n",
    "\n",
    "**Key Benefits:**\n",
    "- Standardize data from different sources (marathons, fell races, parkruns, etc.)\n",
    "- Type validation and automatic field conversion\n",
    "- Flexible column mapping for different data formats\n",
    "- Consistent API for analysis code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393342f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's start by importing Pydantic, pandas, and other necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcb3d0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydantic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Import the new Pydantic models from running_results\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrunning_results\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     NormalizedRaceResult,\n\u001b[1;32m     10\u001b[0m     ColumnMapping,\n\u001b[1;32m     11\u001b[0m     TimeParser,\n\u001b[1;32m     12\u001b[0m     RaceResultsNormalizer,\n\u001b[1;32m     13\u001b[0m     RaceCategory,\n\u001b[1;32m     14\u001b[0m     Gender,\n\u001b[1;32m     15\u001b[0m     normalize_race_results\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Libraries imported successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/running-results/running_results/__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KentigernPlot, RacePlotter\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RaceStatistics, RaceComparison\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     NormalizedRaceResult,\n\u001b[1;32m     22\u001b[0m     ColumnMapping,\n\u001b[1;32m     23\u001b[0m     TimeParser,\n\u001b[1;32m     24\u001b[0m     RaceResultsNormalizer,\n\u001b[1;32m     25\u001b[0m     RaceCategory,\n\u001b[1;32m     26\u001b[0m     Gender,\n\u001b[1;32m     27\u001b[0m     normalize_race_results,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRaceDataFetcher\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSVRaceData\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_race_results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     50\u001b[0m ]\n",
      "File \u001b[0;32m~/projects/running-results/running_results/models.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mPydantic models for normalizing and validating race results data.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    >>> # Now all results have consistent field names\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, field_validator, ValidationInfo\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, List, Dict, Any\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, List, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the new Pydantic models from running_results\n",
    "from running_results.models import (\n",
    "    NormalizedRaceResult,\n",
    "    ColumnMapping,\n",
    "    TimeParser,\n",
    "    RaceResultsNormalizer,\n",
    "    RaceCategory,\n",
    "    Gender,\n",
    "    normalize_race_results\n",
    ")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b8eaa",
   "metadata": {},
   "source": [
    "## 2. Define Pydantic Models for Race Data\n",
    "\n",
    "The Pydantic models have already been defined in `running_results/models.py`. Let's explore the key components:\n",
    "\n",
    "**`NormalizedRaceResult`**: The core schema that all race results are normalized to. It includes:\n",
    "- **Position fields**: `position_overall`, `position_gender`, `position_category`\n",
    "- **Participant info**: `name`, `bib_number`, `gender`, `age_category`, `club`\n",
    "- **Time fields**: `finish_time_seconds`, `chip_time_seconds`, `gun_time_seconds` (with automatic conversion to minutes)\n",
    "- **Metadata**: `race_name`, `race_date`, `race_year`, `race_category`\n",
    "\n",
    "**`ColumnMapping`**: Defines how columns in your source data map to normalized fields.\n",
    "\n",
    "**`RaceResultsNormalizer`**: The main class that handles normalization from arbitrary DataFrame formats.\n",
    "\n",
    "Let's see an example of the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf4fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormalizedRaceResult Schema:\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NormalizedRaceResult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalizedRaceResult Schema:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mNormalizedRaceResult\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_json_schema())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NormalizedRaceResult' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the NormalizedRaceResult schema\n",
    "print(\"NormalizedRaceResult Schema:\")\n",
    "print(\"=\" * 70)\n",
    "print(NormalizedRaceResult.model_json_schema())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae41163",
   "metadata": {},
   "source": [
    "## 3. Parse and Validate Race Results\n",
    "\n",
    "Let's load some real race data and normalize it. We'll use the Edinburgh Marathon and GSR results datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Edinburgh Marathon data\n",
    "print(\"Loading Edinburgh Marathon 2024 data...\")\n",
    "edinburgh_df = pd.read_csv('edinburgh-marathon-2024.csv')\n",
    "print(f\"Shape: {edinburgh_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(edinburgh_df.head(2))\n",
    "print(\"\\nColumns:\")\n",
    "print(edinburgh_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ef1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how Edinburgh Marathon columns map to our standard schema\n",
    "edinburgh_mapping = ColumnMapping(\n",
    "    position_overall='Position (Overall)',\n",
    "    position_category='Position (Category)',\n",
    "    name='Name Number',\n",
    "    club='Club',\n",
    "    chip_time_seconds='Chip Time (seconds)',\n",
    "    gun_time_seconds='Gun Time (seconds)',\n",
    "    age_category='Category'\n",
    ")\n",
    "\n",
    "# Create normalizer for Edinburgh Marathon\n",
    "edinburgh_normalizer = RaceResultsNormalizer(\n",
    "    mapping=edinburgh_mapping,\n",
    "    race_name='Edinburgh Marathon 2024',\n",
    "    race_year=2024,\n",
    "    race_category=RaceCategory.MARATHON\n",
    ")\n",
    "\n",
    "# Normalize the data\n",
    "edinburgh_normalized = edinburgh_normalizer.normalize(\n",
    "    edinburgh_df, \n",
    "    return_dataframe=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Normalized {len(edinburgh_normalized)} Edinburgh Marathon results\")\n",
    "print(\"\\nNormalized columns:\")\n",
    "print(edinburgh_normalized.columns.tolist())\n",
    "print(\"\\nFirst normalized result:\")\n",
    "print(edinburgh_normalized.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9683be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GSR (Great Scottish Run) results\n",
    "print(\"\\nLoading GSR 2022 results...\")\n",
    "gsr_df = pd.read_csv('gsr-results-final-2022.csv')\n",
    "print(f\"Shape: {gsr_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(gsr_df.head(2))\n",
    "print(\"\\nColumns:\")\n",
    "print(gsr_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSR has a completely different schema - let's define the mapping\n",
    "gsr_mapping = ColumnMapping(\n",
    "    position_overall='Pos',\n",
    "    name='Name',\n",
    "    bib_number='Bib',\n",
    "    club='Club',\n",
    "    finish_time_minutes='Finish Time'  # Already in minutes for this dataset\n",
    ")\n",
    "\n",
    "# Create normalizer for GSR - notice auto_detect can help too!\n",
    "gsr_normalizer = RaceResultsNormalizer(\n",
    "    mapping=gsr_mapping,\n",
    "    race_name='Great Scottish Run 2022',\n",
    "    race_year=2022,\n",
    "    race_category=RaceCategory.TEN_K\n",
    ")\n",
    "\n",
    "# Normalize the GSR data\n",
    "gsr_normalized = gsr_normalizer.normalize(\n",
    "    gsr_df,\n",
    "    return_dataframe=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Normalized {len(gsr_normalized)} GSR results\")\n",
    "print(\"\\nFirst normalized result:\")\n",
    "print(gsr_normalized.iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13cb7b4",
   "metadata": {},
   "source": [
    "## 4. Handle Missing and Inconsistent Data\n",
    "\n",
    "Pydantic validation automatically handles missing data and type conversions. Let's demonstrate the flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two datasets to see how they're now unified\n",
    "print(\"Comparison of normalized datasets:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nEdinburgh Marathon:\")\n",
    "print(f\"  - Columns available: {edinburgh_normalized.notna().sum()}\")\n",
    "print(f\"  - Name field: {edinburgh_normalized['name'].notna().sum()} non-null\")\n",
    "print(f\"  - Chip time seconds: {edinburgh_normalized['chip_time_seconds'].notna().sum()} non-null\")\n",
    "print(f\"  - Club field: {edinburgh_normalized['club'].notna().sum()} non-null\")\n",
    "\n",
    "print(f\"\\nGSR:\")\n",
    "print(f\"  - Name field: {gsr_normalized['name'].notna().sum()} non-null\")\n",
    "print(f\"  - Finish time minutes: {gsr_normalized['finish_time_minutes'].notna().sum()} non-null\")\n",
    "print(f\"  - Club field: {gsr_normalized['club'].notna().sum()} non-null\")\n",
    "print(f\"  - Chip time (not in source): {gsr_normalized['chip_time_seconds'].notna().sum()} non-null\")\n",
    "\n",
    "print(\"\\n✓ Both datasets now have the same schema!\")\n",
    "print(\"✓ Missing data is preserved as null values\")\n",
    "print(\"✓ Analysis code can now work with both datasets seamlessly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c39314",
   "metadata": {},
   "source": [
    "## 5. Create Utility Functions for Data Standardization\n",
    "\n",
    "Now we can write general analysis code that works with any normalized race dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_race_results(normalized_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Generic analysis function that works on any normalized race results.\n",
    "    \n",
    "    This demonstrates how once you have normalized data, you can write\n",
    "    analysis code that works across all races without modification.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    if 'finish_time_minutes' in normalized_df.columns:\n",
    "        time_col = 'finish_time_minutes'\n",
    "    elif 'chip_time_minutes' in normalized_df.columns:\n",
    "        time_col = 'chip_time_minutes'\n",
    "    else:\n",
    "        time_col = None\n",
    "    \n",
    "    if time_col:\n",
    "        valid_times = normalized_df[time_col].dropna()\n",
    "        results['time_stats'] = {\n",
    "            'count': len(valid_times),\n",
    "            'mean_minutes': valid_times.mean(),\n",
    "            'median_minutes': valid_times.median(),\n",
    "            'min_minutes': valid_times.min(),\n",
    "            'max_minutes': valid_times.max(),\n",
    "            'std_minutes': valid_times.std(),\n",
    "        }\n",
    "    \n",
    "    # Club participation\n",
    "    club_col = normalized_df['club'].dropna()\n",
    "    results['top_clubs'] = club_col.value_counts().head(10).to_dict()\n",
    "    results['club_count'] = club_col.nunique()\n",
    "    \n",
    "    # Position analysis\n",
    "    results['finisher_count'] = normalized_df['position_overall'].notna().sum()\n",
    "    \n",
    "    # Category breakdown if available\n",
    "    if 'age_category' in normalized_df.columns:\n",
    "        category_counts = normalized_df['age_category'].value_counts()\n",
    "        results['categories'] = category_counts.to_dict()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Apply to both races\n",
    "print(\"Edinburgh Marathon 2024 Analysis:\")\n",
    "print(\"-\" * 70)\n",
    "edin_analysis = analyze_race_results(edinburgh_normalized)\n",
    "print(f\"Finishers: {edin_analysis['finisher_count']}\")\n",
    "if 'time_stats' in edin_analysis:\n",
    "    print(f\"Average time: {edin_analysis['time_stats']['mean_minutes']:.1f} minutes\")\n",
    "    print(f\"Median time: {edin_analysis['time_stats']['median_minutes']:.1f} minutes\")\n",
    "print(f\"Clubs represented: {edin_analysis['club_count']}\")\n",
    "print(f\"Top clubs: {list(edin_analysis['top_clubs'].keys())[:5]}\")\n",
    "\n",
    "print(\"\\n\\nGreat Scottish Run 2022 Analysis:\")\n",
    "print(\"-\" * 70)\n",
    "gsr_analysis = analyze_race_results(gsr_normalized)\n",
    "print(f\"Finishers: {gsr_analysis['finisher_count']}\")\n",
    "if 'time_stats' in gsr_analysis:\n",
    "    print(f\"Average time: {gsr_analysis['time_stats']['mean_minutes']:.1f} minutes\")\n",
    "    print(f\"Median time: {gsr_analysis['time_stats']['median_minutes']:.1f} minutes\")\n",
    "print(f\"Clubs represented: {gsr_analysis['club_count']}\")\n",
    "print(f\"Top clubs: {list(gsr_analysis['top_clubs'].keys())[:5]}\")\n",
    "\n",
    "print(\"\\n✓ Same analysis code works for both races with different formats!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725ad93",
   "metadata": {},
   "source": [
    "## 6. Test Regularisation with Sample Data\n",
    "\n",
    "Let's create and validate a custom race dataset to demonstrate the robustness of the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test dataset with completely different column names and formats\n",
    "test_data = pd.DataFrame({\n",
    "    'Rank': [1, 2, 3, 4, 5],\n",
    "    'Athlete': ['Alice Smith', 'Bob Johnson', 'Charlie Brown', 'Diana Prince', 'Eve Wilson'],\n",
    "    'BiB': [101, 102, 103, 104, 105],\n",
    "    'Team': ['Running Club A', 'Team B', 'Independent', 'Running Club A', 'Team C'],\n",
    "    'Time_HM': ['1:30:45', '1:35:22', '1:42:18', '1:45:30', '1:50:15'],  # HH:MM:SS format\n",
    "    'AgeGroup': ['30-39', '40-49', '20-29', '50-59', '35-44']\n",
    "})\n",
    "\n",
    "print(\"Test dataset (various formats):\")\n",
    "print(test_data)\n",
    "\n",
    "# Define mapping for this test data\n",
    "test_mapping = ColumnMapping(\n",
    "    position_overall='Rank',\n",
    "    name='Athlete',\n",
    "    bib_number='BiB',\n",
    "    club='Team',\n",
    "    finish_time_minutes='Time_HM',\n",
    "    age_category='AgeGroup'\n",
    ")\n",
    "\n",
    "# Create normalizer with custom time format parser\n",
    "test_parser = TimeParser(format='HH:MM:SS')\n",
    "test_normalizer = RaceResultsNormalizer(\n",
    "    mapping=test_mapping,\n",
    "    time_parser=test_parser,\n",
    "    race_name='Test Local 5K Race',\n",
    "    race_year=2024,\n",
    "    race_category=RaceCategory.FIVE_K\n",
    ")\n",
    "\n",
    "# Normalize\n",
    "test_normalized = test_normalizer.normalize(test_data, return_dataframe=True)\n",
    "\n",
    "print(\"\\nNormalized test data:\")\n",
    "print(test_normalized[['position_overall', 'name', 'finish_time_minutes', \n",
    "                        'finish_time_seconds', 'club', 'race_name']])\n",
    "\n",
    "print(\"\\n✓ Test passed! Irregular data formats were successfully normalized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e1773",
   "metadata": {},
   "source": [
    "## Key Advantages of This Approach\n",
    "\n",
    "**1. Type Safety**: Pydantic validates all data types automatically\n",
    "- Invalid values are either coerced or marked as None\n",
    "- Prevents runtime errors in downstream analysis\n",
    "\n",
    "**2. Flexibility**: Supports multiple data formats\n",
    "- Different column names\n",
    "- Different time formats (HH:MM:SS, MM:SS, seconds)\n",
    "- Optional fields with sensible defaults\n",
    "\n",
    "**3. Reusable Analysis Code**: Write once, run anywhere\n",
    "- Same functions work for marathons, parkruns, fell races, etc.\n",
    "- No need to handle each data source differently\n",
    "\n",
    "**4. Auto-detection**: Optional automatic column mapping\n",
    "- For well-formatted data, no manual mapping needed\n",
    "- Falls back to explicit mapping when needed\n",
    "\n",
    "**5. Extensibility**: Easy to add new fields or validations\n",
    "- Add custom validators to the NormalizedRaceResult model\n",
    "- Extend for race-specific requirements\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you have normalized data, you can:\n",
    "\n",
    "1. **Combine multiple races** for comparative analysis\n",
    "2. **Create reusable analysis functions** that work across all races\n",
    "3. **Build pipelines** that automatically normalize new race data\n",
    "4. **Export to standard formats** (JSON, CSV) for sharing with other tools\n",
    "\n",
    "The models in `running_results/models.py` include comprehensive validation and error handling to ensure data quality!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
